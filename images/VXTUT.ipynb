{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: voxelmorph in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (1.21.2)\n",
      "Requirement already satisfied: nibabel in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (3.2.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (0.18.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (2.10.0)\n",
      "Requirement already satisfied: neurite in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from voxelmorph) (0.1)\n",
      "Requirement already satisfied: six in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from h5py->voxelmorph) (1.16.0)\n",
      "Requirement already satisfied: pystrum in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite->voxelmorph) (0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite->voxelmorph) (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite->voxelmorph) (4.62.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite->voxelmorph) (3.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite->voxelmorph) (21.3)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-image->voxelmorph) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-image->voxelmorph) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-image->voxelmorph) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-image->voxelmorph) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-learn->neurite->voxelmorph) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-learn->neurite->voxelmorph) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from tqdm->neurite->voxelmorph) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: neurite in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (1.21.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (4.62.3)\n",
      "Requirement already satisfied: six in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (1.16.0)\n",
      "Requirement already satisfied: pystrum in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (0.1)\n",
      "Requirement already satisfied: nibabel in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (3.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (3.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from neurite) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from matplotlib->neurite) (0.11.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-learn->neurite) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from scikit-learn->neurite) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mgwei\\anaconda3\\lib\\site-packages (from tqdm->neurite) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install voxelmorph, which will also install dependencies: neurite and pystrum\n",
    "%pip install voxelmorph\n",
    "%pip install neurite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'neurite' has no attribute 'modelio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30180/3961627458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# local imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mvoxelmorph\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvxm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mneurite\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mne\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgwei\\Desktop\\GitHub\\voxelmorph\\voxelmorph\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please install tensorflow to use this voxelmorph backend'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgwei\\Desktop\\GitHub\\voxelmorph\\voxelmorph\\tf\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgwei\\Desktop\\GitHub\\voxelmorph\\voxelmorph\\tf\\networks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mVxmDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadableModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m     44\u001b[0m     \u001b[0mVoxelMorph\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mnonlinear\u001b[0m \u001b[0mregistration\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'neurite' has no attribute 'modelio'"
     ]
    }
   ],
   "source": [
    "# local imports\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should most often have this import together with all other imports at the top, \n",
    "# but we include here here explicitly to show where data comes from\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data. \n",
    "# `mnist.load_data()` already splits our data into train and test.  \n",
    "(x_train_load) = np.load(\"imgds2.npy\")\n",
    "\n",
    "digit_sel = 20\n",
    "\n",
    "# extract only instances of the digit 5\n",
    "x_train = x_train_load\n",
    "# y_train = y_train_load[y_train_load==digit_sel]\n",
    "# x_test = x_test_load[y_test_load==digit_sel, ...]\n",
    "# y_test = y_test_load[y_test_load==digit_sel]\n",
    "\n",
    "# let's get some shapes to understand what we loaded.\n",
    "# print('shape of x_train: {}, y_train: {}'.format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_val = 0  # keep 1,000 subjects for validation\n",
    "x_val = x_train  # this indexing means \"the last nb_val entries\" of the zeroth axis\n",
    "# y_val = y_train[-nb_val:]\n",
    "# x_train = x_train[:-nb_val, ...]\n",
    "# y_train = y_train[:-nb_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  2  7 15 16]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30180/295897096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_digits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_colorbars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ne' is not defined"
     ]
    }
   ],
   "source": [
    "nb_vis = 5\n",
    "\n",
    "# choose nb_vis sample indexes\n",
    "idx = np.random.choice(x_train.shape[0], nb_vis, replace=False)\n",
    "print(idx)\n",
    "# idx = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "idx = np.array([13, 14])\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "\n",
    "# plot\n",
    "ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix data\n",
    "x_train = x_train.astype('float')/255\n",
    "# x_val = x_val.astype('float')/255\n",
    "# x_test = x_test.astype('float')/255\n",
    "\n",
    "# verify\n",
    "print('training maximum value', x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-visualize\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_amount = ((0, 0), (0,0), (0,0))\n",
    "\n",
    "# fix data\n",
    "x_train = np.pad(x_train, pad_amount, 'constant')\n",
    "# x_val = np.pad(x_val, pad_amount, 'constant')\n",
    "# x_test = np.pad(x_test, pad_amount, 'constant')\n",
    "\n",
    "# verify\n",
    "print('shape of training data', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure unet input shape (concatenation of moving and fixed images)\n",
    "ndim = 2\n",
    "unet_input_features = 2\n",
    "inshape = (*x_train.shape[1:], unet_input_features)\n",
    "print(inshape)\n",
    "\n",
    "# configure unet features \n",
    "nb_features = [\n",
    "    [512, 512, 512, 512],         # encoder features\n",
    "    [512, 512, 512, 512, 512, 256]  # decoder features\n",
    "]\n",
    "\n",
    "# build model\n",
    "unet = vxm.networks.Unet(inshape=inshape, nb_features=nb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input shape: ', unet.input.shape)\n",
    "print('output shape:', unet.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the results into a flow field.\n",
    "disp_tensor = tf.keras.layers.Conv2D(ndim, kernel_size=3, padding='same', name='disp')(unet.output)\n",
    "\n",
    "# check tensor shape\n",
    "print('displacement tensor:', disp_tensor.shape)\n",
    "\n",
    "# using keras, we can easily form new models via tensor pointers\n",
    "def_model = tf.keras.models.Model(unet.inputs, disp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build transformer layer\n",
    "spatial_transformer = vxm.layers.SpatialTransformer(name='transformer')\n",
    "\n",
    "# extract the first frame (i.e. the \"moving\" image) from unet input tensor\n",
    "moving_image = tf.expand_dims(unet.input[..., 0], axis=-1)\n",
    "\n",
    "# warp the moving image with the transformer\n",
    "moved_image_tensor = spatial_transformer([moving_image, disp_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [moved_image_tensor, disp_tensor]\n",
    "vxm_model = tf.keras.models.Model(inputs=unet.inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model using VxmDense\n",
    "inshape = x_train.shape[1:]\n",
    "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input shape: ', ', '.join([str(t.shape) for t in vxm_model.inputs]))\n",
    "print('output shape:', ', '.join([str(t.shape) for t in vxm_model.outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxelmorph has a variety of custom loss classes\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vxm_data_generator(x_data, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generator that takes in data of size [N, H, W], and yields data for\n",
    "    our custom vxm model. Note that we need to provide numpy data for each\n",
    "    input, and each output.\n",
    "\n",
    "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
    "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
    "    \"\"\"\n",
    "\n",
    "    # preliminary sizing\n",
    "    vol_shape = x_data.shape[1:] # extract data shape\n",
    "    ndims = len(vol_shape)\n",
    "    \n",
    "    # prepare a zero array the size of the deformation\n",
    "    # we'll explain this below\n",
    "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
    "    \n",
    "    while True:\n",
    "        # prepare inputs:\n",
    "        # images need to be of the size [batch_size, H, W, 1]\n",
    "        idx1 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
    "        moving_images = x_data[idx1, ..., np.newaxis]\n",
    "        idx2 = np.random.randint(0, x_data.shape[0], size=batch_size)\n",
    "        fixed_images = x_data[idx2, ..., np.newaxis]\n",
    "        inputs = [moving_images, fixed_images]\n",
    "        \n",
    "        # prepare outputs (the 'true' moved image):\n",
    "        # of course, we don't have this, but we know we want to compare \n",
    "        # the resulting moved image with the fixed image. \n",
    "        # we also wish to penalize the deformation field. \n",
    "        outputs = [fixed_images, zero_phi]\n",
    "        \n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = vxm_data_generator(x_train)\n",
    "in_sample, out_sample = next(train_generator)\n",
    "\n",
    "# visualize\n",
    "images = [img[0, :, :, 0] for img in in_sample + out_sample] \n",
    "titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "steps_per_epoch = 100\n",
    "hist = vxm_model.fit_generator(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(hist, loss_name='loss'):\n",
    "    # Simple function to plot training history.\n",
    "    plt.figure()\n",
    "    plt.plot(hist.epoch, hist.history[loss_name], '.-')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get some data\n",
    "val_generator = vxm_data_generator(x_val, batch_size = 1)\n",
    "val_input, _ = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit is a 'jupyter magic' that times the given line over several runs\n",
    "%timeit vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "images = [img[0, :, :, 0] for img in val_input + val_pred] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne.plot.flow([val_pred[1].squeeze()], width=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only instances of the digit 7\n",
    "x_sevens = x_train_load[y_train_load==7, ...].astype('float') / 255\n",
    "x_sevens = np.pad(x_sevens, pad_amount, 'constant')\n",
    "\n",
    "# predict\n",
    "seven_generator = vxm_data_generator(x_sevens, batch_size=1)\n",
    "seven_sample, _ = next(seven_generator)\n",
    "seven_pred = vxm_model.predict(seven_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "images = [img[0, :, :, 0] for img in seven_sample + seven_pred] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 5\n",
    "val_pred = vxm_model.predict([f * factor for f in val_input])\n",
    "\n",
    "# visualizeb\n",
    "images = [img[0, :, :, 0] for img in val_input + val_pred] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MRI tutorial data\n",
    "!wget https://surfer.nmr.mgh.harvard.edu/pub/data/voxelmorph/tutorial_data.tar.gz -O data.tar.gz\n",
    "!tar -xzvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('tutorial_data.npz')\n",
    "x_train = npz['train']\n",
    "x_val = npz['validate']\n",
    "\n",
    "# the 208 volumes are of size 160x192\n",
    "vol_shape = x_train.shape[1:]\n",
    "print('train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some brains\n",
    "nb_vis = 5\n",
    "idx = np.random.randint(0, x_train.shape[0], [5,])\n",
    "example_digits = [f for f in x_train[idx, ...]]\n",
    "\n",
    "# visualize\n",
    "ne.plot.slices(example_digits, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet\n",
    "vxm_model = vxm.networks.VxmDense(vol_shape, nb_features, int_steps=0)\n",
    "\n",
    "# losses and loss weights\n",
    "losses = ['mse', vxm.losses.Grad('l2').loss]\n",
    "loss_weights = [1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = vxm_data_generator(x_train, batch_size=8)\n",
    "in_sample, out_sample = next(train_generator)\n",
    "\n",
    "# visualize\n",
    "images = [img[0, :, :, 0] for img in in_sample + out_sample]\n",
    "titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = vxm_model.fit_generator(train_generator, epochs=5, steps_per_epoch=5, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before, let's visualize what happened\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model weights\n",
    "vxm_model.load_weights('brain_2d_smooth.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the validation data generator\n",
    "val_generator = vxm_data_generator(x_val, batch_size = 1)\n",
    "val_input, _ = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize registration\n",
    "images = [img[0, :, :, 0] for img in val_input + val_pred] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize flow\n",
    "flow = val_pred[1].squeeze()[::3,::3]\n",
    "ne.plot.flow([flow], width=5);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d58e2ade7fa243b85b4ec6068a879921c2a4346755fefc46ece503de67743ca9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
